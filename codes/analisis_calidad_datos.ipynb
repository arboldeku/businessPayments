{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Informe del Análisis de Calidad de Datos**\n",
    "\n",
    "Resultados del análisis de calidad de los datos, identificando problemas encontrados (como valores faltantes o inconsistencias) y detallando las soluciones implementadas para garantizar la confiabilidad del análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information extract - cash request - data analyst.csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23970 entries, 0 to 23969\n",
      "Data columns (total 16 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          23970 non-null  int64  \n",
      " 1   amount                      23970 non-null  float64\n",
      " 2   status                      23970 non-null  object \n",
      " 3   created_at                  23970 non-null  object \n",
      " 4   updated_at                  23970 non-null  object \n",
      " 5   user_id                     21867 non-null  float64\n",
      " 6   moderated_at                16035 non-null  object \n",
      " 7   deleted_account_id          2104 non-null   float64\n",
      " 8   reimbursement_date          23970 non-null  object \n",
      " 9   cash_request_received_date  16289 non-null  object \n",
      " 10  money_back_date             16543 non-null  object \n",
      " 11  transfer_type               23970 non-null  object \n",
      " 12  send_at                     16641 non-null  object \n",
      " 13  recovery_status             3330 non-null   object \n",
      " 14  reco_creation               3330 non-null   object \n",
      " 15  reco_last_update            3330 non-null   object \n",
      "dtypes: float64(3), int64(1), object(12)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "cash_request_df = pd.read_csv('../project_dataset/extract - cash request - data analyst.csv')\n",
    "fees_df = pd.read_csv('../project_dataset/extract - fees - data analyst - .csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Basic Information extract - cash request - data analyst.csv:\")\n",
    "print(cash_request_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Information extract - fees - data analyst - .csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               21061 non-null  int64  \n",
      " 1   cash_request_id  21057 non-null  float64\n",
      " 2   type             21061 non-null  object \n",
      " 3   status           21061 non-null  object \n",
      " 4   category         2196 non-null   object \n",
      " 5   total_amount     21061 non-null  float64\n",
      " 6   reason           21061 non-null  object \n",
      " 7   created_at       21061 non-null  object \n",
      " 8   updated_at       21061 non-null  object \n",
      " 9   paid_at          15531 non-null  object \n",
      " 10  from_date        7766 non-null   object \n",
      " 11  to_date          7766 non-null   object \n",
      " 12  charge_moment    21061 non-null  object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 2.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Basic Information extract - fees - data analyst - .csv:\")\n",
    "print(fees_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data quality\n",
    "def evaluate_data_quality(df, df_name):\n",
    "    print(f\"Evaluating data quality for {df_name}...\\n\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    print(f\"Missing values in {df_name}:\\n{missing_values}\\n\")\n",
    "    \n",
    "    # Check for duplicate rows\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"Duplicate rows in {df_name}: {duplicate_rows}\\n\")\n",
    "    \n",
    "    # Check for inconsistencies (example: negative values in columns that should only have positive values)\n",
    "    for column in df.select_dtypes(include=['number']).columns:\n",
    "        negative_values = (df[column] < 0).sum()\n",
    "        if negative_values > 0:\n",
    "            print(f\"Column '{column}' in {df_name} has {negative_values} negative values.\\n\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    #print(f\"Summary statistics for {df_name}:\\n{df.describe()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for extract - cash request - data analyst.csv...\n",
      "\n",
      "Missing values in extract - cash request - data analyst.csv:\n",
      "id                                0\n",
      "amount                            0\n",
      "status                            0\n",
      "created_at                        0\n",
      "updated_at                        0\n",
      "user_id                        2103\n",
      "moderated_at                   7935\n",
      "deleted_account_id            21866\n",
      "reimbursement_date                0\n",
      "cash_request_received_date     7681\n",
      "money_back_date                7427\n",
      "transfer_type                     0\n",
      "send_at                        7329\n",
      "recovery_status               20640\n",
      "reco_creation                 20640\n",
      "reco_last_update              20640\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows in extract - cash request - data analyst.csv: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data quality for extract - cash request - data analyst dataset\n",
    "evaluate_data_quality(cash_request_df, 'extract - cash request - data analyst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for extract - fees - data analyst - .csv...\n",
      "\n",
      "Missing values in extract - fees - data analyst - .csv:\n",
      "id                     0\n",
      "cash_request_id        4\n",
      "type                   0\n",
      "status                 0\n",
      "category           18865\n",
      "total_amount           0\n",
      "reason                 0\n",
      "created_at             0\n",
      "updated_at             0\n",
      "paid_at             5530\n",
      "from_date          13295\n",
      "to_date            13295\n",
      "charge_moment          0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows in extract - fees - data analyst - .csv: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data quality for extract - fees - data analyst dataset\n",
    "evaluate_data_quality(fees_df, 'extract - fees - data analyst - .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of add '_fee' to each column of extract - fees - data analyst - .csv:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21061 entries, 0 to 21060\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id_fee             21061 non-null  int64  \n",
      " 1   cash_request_id    21057 non-null  float64\n",
      " 2   type_fee           21061 non-null  object \n",
      " 3   status_fee         21061 non-null  object \n",
      " 4   category_fee       2196 non-null   object \n",
      " 5   total_amount_fee   21061 non-null  float64\n",
      " 6   reason_fee         21061 non-null  object \n",
      " 7   created_at_fee     21061 non-null  object \n",
      " 8   updated_at_fee     21061 non-null  object \n",
      " 9   paid_at_fee        15531 non-null  object \n",
      " 10  from_date_fee      7766 non-null   object \n",
      " 11  to_date_fee        7766 non-null   object \n",
      " 12  charge_moment_fee  21061 non-null  object \n",
      "dtypes: float64(2), int64(1), object(10)\n",
      "memory usage: 2.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns of the fees dataset\n",
    "fees_df_modified = fees_df.rename(columns=lambda x: x + '_fee' if x != 'cash_request_id' else x)\n",
    "print(\"Result of add '_fee' to each column of extract - fees - data analyst - .csv:\")\n",
    "print(fees_df_modified.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged successfully.\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets on matching IDs\n",
    "merged_df = pd.merge(cash_request_df, fees_df_modified, left_on='id', right_on='cash_request_id', how='inner')\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv('../project_dataset/merged_cash_request_fees.csv', index=False)\n",
    "print(\"Datasets merged successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged datasets based on 'id' (extract - cash request - data analyst) and 'cash_request_id' (extract - fees - data analyst) columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21057 entries, 0 to 21056\n",
      "Data columns (total 29 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          21057 non-null  int64  \n",
      " 1   amount                      21057 non-null  float64\n",
      " 2   status                      21057 non-null  object \n",
      " 3   created_at                  21057 non-null  object \n",
      " 4   updated_at                  21057 non-null  object \n",
      " 5   user_id                     20151 non-null  float64\n",
      " 6   moderated_at                11284 non-null  object \n",
      " 7   deleted_account_id          906 non-null    float64\n",
      " 8   reimbursement_date          21057 non-null  object \n",
      " 9   cash_request_received_date  19763 non-null  object \n",
      " 10  money_back_date             19701 non-null  object \n",
      " 11  transfer_type               21057 non-null  object \n",
      " 12  send_at                     17570 non-null  object \n",
      " 13  recovery_status             6894 non-null   object \n",
      " 14  reco_creation               6894 non-null   object \n",
      " 15  reco_last_update            6894 non-null   object \n",
      " 16  id_fee                      21057 non-null  int64  \n",
      " 17  cash_request_id             21057 non-null  float64\n",
      " 18  type_fee                    21057 non-null  object \n",
      " 19  status_fee                  21057 non-null  object \n",
      " 20  category_fee                2196 non-null   object \n",
      " 21  total_amount_fee            21057 non-null  float64\n",
      " 22  reason_fee                  21057 non-null  object \n",
      " 23  created_at_fee              21057 non-null  object \n",
      " 24  updated_at_fee              21057 non-null  object \n",
      " 25  paid_at_fee                 15531 non-null  object \n",
      " 26  from_date_fee               7766 non-null   object \n",
      " 27  to_date_fee                 7766 non-null   object \n",
      " 28  charge_moment_fee           21057 non-null  object \n",
      "dtypes: float64(5), int64(2), object(22)\n",
      "memory usage: 4.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Merged datasets based on 'id' (extract - cash request - data analyst) and 'cash_request_id' (extract - fees - data analyst) columns:\")\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for merged_cash_request_fees.csv...\n",
      "\n",
      "Missing values in merged_cash_request_fees.csv:\n",
      "id                                0\n",
      "amount                            0\n",
      "status                            0\n",
      "created_at                        0\n",
      "updated_at                        0\n",
      "user_id                         906\n",
      "moderated_at                   9773\n",
      "deleted_account_id            20151\n",
      "reimbursement_date                0\n",
      "cash_request_received_date     1294\n",
      "money_back_date                1356\n",
      "transfer_type                     0\n",
      "send_at                        3487\n",
      "recovery_status               14163\n",
      "reco_creation                 14163\n",
      "reco_last_update              14163\n",
      "id_fee                            0\n",
      "cash_request_id                   0\n",
      "type_fee                          0\n",
      "status_fee                        0\n",
      "category_fee                  18861\n",
      "total_amount_fee                  0\n",
      "reason_fee                        0\n",
      "created_at_fee                    0\n",
      "updated_at_fee                    0\n",
      "paid_at_fee                    5526\n",
      "from_date_fee                 13291\n",
      "to_date_fee                   13291\n",
      "charge_moment_fee                 0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows in merged_cash_request_fees.csv: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data quality for merged dataset\n",
    "evaluate_data_quality(merged_df, 'merged_cash_request_fees.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codes for missing information based on Lexique - Data Analyst.xlsx:\n",
      "                   Column Name      Code  \\\n",
      "0                      user_id      Null   \n",
      "1                 moderated_at        98   \n",
      "2           deleted_account_id  98888888   \n",
      "3   cash_request_received_date        98   \n",
      "4              money_back_date      Null   \n",
      "5                      send_at      Null   \n",
      "6              recovery_status        98   \n",
      "7                reco_creation      Null   \n",
      "8             reco_last_update      Null   \n",
      "9                 category_fee      Null   \n",
      "10                 paid_at_fee      Null   \n",
      "11               from_date_fee        98   \n",
      "12                 to_date_fee        98   \n",
      "\n",
      "                                      Explanation  \n",
      "0                                               ?  \n",
      "1                       No needed a manual review  \n",
      "2                              No deleted account  \n",
      "3                     No sent a SEPA direct debit  \n",
      "4                                               ?  \n",
      "5                                               ?  \n",
      "6   The case request never had a payment incident  \n",
      "7                                               ?  \n",
      "8                                               ?  \n",
      "9                                               ?  \n",
      "10                                              ?  \n",
      "11                               No postpone fees  \n",
      "12                              No postpones fees  \n"
     ]
    }
   ],
   "source": [
    "# Define the data for the table\n",
    "data = {\n",
    "    'Column Name': [\n",
    "        'user_id', 'moderated_at', 'deleted_account_id', 'cash_request_received_date', \n",
    "        'money_back_date', 'send_at', 'recovery_status', 'reco_creation', 'reco_last_update',\n",
    "        'category_fee', 'paid_at_fee', 'from_date_fee', 'to_date_fee'\n",
    "    ],\n",
    "    'Code': [\n",
    "        'Null', '98', '98888888', '98', \n",
    "        'Null', 'Null', '98', 'Null', 'Null',\n",
    "        'Null', 'Null', '98', '98'\n",
    "    ],\n",
    "    'Explanation': [\n",
    "        '?', 'No needed a manual review', 'No deleted account', 'No sent a SEPA direct debit', \n",
    "        '?', '?', 'The case request never had a payment incident', '?', '?',\n",
    "        '?', '?', 'No postpone fees', 'No postpones fees'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "missing_info_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(\"Codes for missing information based on Lexique - Data Analyst.xlsx:\")\n",
    "print(missing_info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values have been filled and the cleaned dataset has been saved.\n",
      "Evaluating data quality for cleaned_merged_cash_request_fees...\n",
      "\n",
      "Missing values in cleaned_merged_cash_request_fees:\n",
      "id                            0\n",
      "amount                        0\n",
      "status                        0\n",
      "created_at                    0\n",
      "updated_at                    0\n",
      "user_id                       0\n",
      "moderated_at                  0\n",
      "deleted_account_id            0\n",
      "reimbursement_date            0\n",
      "cash_request_received_date    0\n",
      "money_back_date               0\n",
      "transfer_type                 0\n",
      "send_at                       0\n",
      "recovery_status               0\n",
      "reco_creation                 0\n",
      "reco_last_update              0\n",
      "id_fee                        0\n",
      "cash_request_id               0\n",
      "type_fee                      0\n",
      "status_fee                    0\n",
      "category_fee                  0\n",
      "total_amount_fee              0\n",
      "reason_fee                    0\n",
      "created_at_fee                0\n",
      "updated_at_fee                0\n",
      "paid_at_fee                   0\n",
      "from_date_fee                 0\n",
      "to_date_fee                   0\n",
      "charge_moment_fee             0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows in cleaned_merged_cash_request_fees: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7z/00rgwf311yn2q_dbm8dwq25m0000gn/T/ipykernel_5122/1476439258.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['deleted_account_id'].fillna(98888888, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with specified values\n",
    "merged_df['user_id'].fillna(\"Null\", inplace=True)\n",
    "merged_df['moderated_at'].fillna(98, inplace=True)\n",
    "merged_df['deleted_account_id'].fillna(98888888, inplace=True)\n",
    "merged_df['cash_request_received_date'].fillna(98, inplace=True)\n",
    "merged_df['money_back_date'].fillna(\"Null\", inplace=True)\n",
    "merged_df['send_at'].fillna(\"Null\", inplace=True)\n",
    "merged_df['recovery_status'].fillna(98, inplace=True)\n",
    "merged_df['reco_creation'].fillna(\"Null\", inplace=True)\n",
    "merged_df['reco_last_update'].fillna(\"Null\", inplace=True)\n",
    "\n",
    "merged_df['category_fee'].fillna(\"Null\", inplace=True)\n",
    "merged_df['paid_at_fee'].fillna(\"Null\", inplace=True)\n",
    "merged_df['from_date_fee'].fillna(98, inplace=True)\n",
    "merged_df['to_date_fee'].fillna(98, inplace=True)\n",
    "\n",
    "# Save the cleaned dataset\n",
    "merged_df.to_csv('../project_dataset/cleaned_merged_cash_request_fees.csv', index=False)\n",
    "\n",
    "print(\"Missing values have been filled and the cleaned dataset has been saved.\")\n",
    "\n",
    "# Evaluate data quality for cleaned and merged dataset\n",
    "evaluate_data_quality(merged_df, 'cleaned_merged_cash_request_fees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion of the 'created_at' and 'created_at_fee' columns to datetime format:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21057 entries, 0 to 21056\n",
      "Data columns (total 29 columns):\n",
      " #   Column                      Non-Null Count  Dtype              \n",
      "---  ------                      --------------  -----              \n",
      " 0   id                          21057 non-null  int64              \n",
      " 1   amount                      21057 non-null  float64            \n",
      " 2   status                      21057 non-null  object             \n",
      " 3   created_at                  21057 non-null  datetime64[ns, UTC]\n",
      " 4   updated_at                  21057 non-null  object             \n",
      " 5   user_id                     21057 non-null  object             \n",
      " 6   moderated_at                21057 non-null  object             \n",
      " 7   deleted_account_id          21057 non-null  float64            \n",
      " 8   reimbursement_date          21057 non-null  object             \n",
      " 9   cash_request_received_date  21057 non-null  object             \n",
      " 10  money_back_date             21057 non-null  object             \n",
      " 11  transfer_type               21057 non-null  object             \n",
      " 12  send_at                     21057 non-null  object             \n",
      " 13  recovery_status             21057 non-null  object             \n",
      " 14  reco_creation               21057 non-null  object             \n",
      " 15  reco_last_update            21057 non-null  object             \n",
      " 16  id_fee                      21057 non-null  int64              \n",
      " 17  cash_request_id             21057 non-null  float64            \n",
      " 18  type_fee                    21057 non-null  object             \n",
      " 19  status_fee                  21057 non-null  object             \n",
      " 20  category_fee                21057 non-null  object             \n",
      " 21  total_amount_fee            21057 non-null  float64            \n",
      " 22  reason_fee                  21057 non-null  object             \n",
      " 23  created_at_fee              21057 non-null  datetime64[ns, UTC]\n",
      " 24  updated_at_fee              21057 non-null  object             \n",
      " 25  paid_at_fee                 21057 non-null  object             \n",
      " 26  from_date_fee               21057 non-null  object             \n",
      " 27  to_date_fee                 21057 non-null  object             \n",
      " 28  charge_moment_fee           21057 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(4), int64(2), object(21)\n",
      "memory usage: 4.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'created_at' and 'created_at_fee' columns to datetime format\n",
    "merged_df['created_at'] = pd.to_datetime(merged_df['created_at'])\n",
    "merged_df['created_at_fee'] = pd.to_datetime(merged_df['created_at_fee'])\n",
    "\n",
    "print(\"Conversion of the 'created_at' and 'created_at_fee' columns to datetime format:\")\n",
    "print(merged_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calidad de los datos necesarios para las métricas:\n",
    "1. **Frecuencia de Uso del Servicio:** Analizar con qué frecuencia los usuarios de cada cohorte utilizan los servicios de adelanto de efectivo de Business Payments a lo largo del tiempo. (“created_at” “transfer_type”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for column: created_at\n",
      "\n",
      "Missing values in created_at: 0\n",
      "\n",
      "Invalid dates in created_at: 0\n",
      "\n",
      "Evaluating data quality for column: transfer_type\n",
      "\n",
      "Missing values in transfer_type: 0\n",
      "\n",
      "Unique values in transfer_type: ['instant' 'regular']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data quality for 'created_at' and 'transfer_type' columns\n",
    "def evaluate_needed_data_quality_for_frecuency(df, columns):\n",
    "    for column in columns:\n",
    "        print(f\"Evaluating data quality for column: {column}\\n\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values = df[column].isnull().sum()\n",
    "        print(f\"Missing values in {column}: {missing_values}\\n\")\n",
    "        \n",
    "        # Check for inconsistencies (example: invalid dates in 'created_at')\n",
    "        if column == 'created_at':\n",
    "            invalid_dates = pd.to_datetime(df[column], errors='coerce').isnull().sum()\n",
    "            print(f\"Invalid dates in {column}: {invalid_dates}\\n\")\n",
    "        \n",
    "        # Check for unique values in 'transfer_type'\n",
    "        if column == 'transfer_type':\n",
    "            unique_values = df[column].unique()\n",
    "            print(f\"Unique values in {column}: {unique_values}\\n\")\n",
    "\n",
    "# Columns to evaluate\n",
    "columns_to_evaluate = ['created_at', 'transfer_type']\n",
    "\n",
    "# Evaluate data quality\n",
    "evaluate_needed_data_quality_for_frecuency(merged_df, columns_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Tasa de Incidentes:** Determinar la tasa de incidentes, especialmente aquellos relacionados con problemas de pago, en cada cohorte. Identificar variaciones significativas entre cohortes. (“recovery_status: pending, pending_direct_debit”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for column: recovery_status\n",
      "\n",
      "Missing values in recovery_status: 0\n",
      "\n",
      "Count of 'pending' in recovery_status: 1914\n",
      "\n",
      "Count of 'pending_direct_debit' in recovery_status: 34\n",
      "\n",
      "Unique values in recovery_status: [98 'pending' 'completed' 'pending_direct_debit' 'cancelled']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data quality for 'recovery_status' column\n",
    "def evaluate_data_quality_for_recovery_status(df):\n",
    "    column = 'recovery_status'\n",
    "    print(f\"Evaluating data quality for column: {column}\\n\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = df[column].isnull().sum()\n",
    "    print(f\"Missing values in {column}: {missing_values}\\n\")\n",
    "    \n",
    "    # Check for specific values 'pending' and 'pending_direct_debit'\n",
    "    pending_count = df[df[column] == 'pending'].shape[0]\n",
    "    pending_direct_debit_count = df[df[column] == 'pending_direct_debit'].shape[0]\n",
    "    print(f\"Count of 'pending' in {column}: {pending_count}\\n\")\n",
    "    print(f\"Count of 'pending_direct_debit' in {column}: {pending_direct_debit_count}\\n\")\n",
    "    \n",
    "    # Check for unique values in 'recovery_status'\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in {column}: {unique_values}\\n\")\n",
    "\n",
    "# Evaluate data quality\n",
    "evaluate_data_quality_for_recovery_status(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Ingresos Generados por Cohorte:** Calcular el total de ingresos generados por cada cohorte a lo largo del tiempo para evaluar el impacto financiero del comportamiento de los usuarios. (“total_amount” “created_at” “created_at_fee”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating data quality for column: total_amount_fee\n",
      "\n",
      "Missing values in total_amount_fee: 0\n",
      "\n",
      "Negative values in total_amount_fee: 0\n",
      "\n",
      "Evaluating data quality for column: created_at\n",
      "\n",
      "Missing values in created_at: 0\n",
      "\n",
      "Invalid dates in created_at: 0\n",
      "\n",
      "Evaluating data quality for column: created_at_fee\n",
      "\n",
      "Missing values in created_at_fee: 0\n",
      "\n",
      "Invalid dates in created_at_fee: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_amount_fee': {'missing_values': np.int64(0),\n",
       "  'invalid_dates': None,\n",
       "  'negative_values': np.int64(0)},\n",
       " 'created_at': {'missing_values': np.int64(0),\n",
       "  'invalid_dates': np.int64(0),\n",
       "  'negative_values': None},\n",
       " 'created_at_fee': {'missing_values': np.int64(0),\n",
       "  'invalid_dates': np.int64(0),\n",
       "  'negative_values': None}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate data quality for specified columns\n",
    "def evaluate_data_quality_for_income(df, columns):\n",
    "    data_quality_issues = {}\n",
    "    \n",
    "    for column in columns:\n",
    "        print(f\"Evaluating data quality for column: {column}\\n\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values = df[column].isnull().sum()\n",
    "        print(f\"Missing values in {column}: {missing_values}\\n\")\n",
    "        \n",
    "        # Check for inconsistencies (example: invalid dates in 'created_at' and 'created_at_fee')\n",
    "        if column in ['created_at', 'created_at_fee']:\n",
    "            invalid_dates = pd.to_datetime(df[column], errors='coerce').isnull().sum()\n",
    "            print(f\"Invalid dates in {column}: {invalid_dates}\\n\")\n",
    "        \n",
    "        # Check for negative values in 'total_amount'\n",
    "        if column == 'total_amount_fee':\n",
    "            negative_values = (df[column] < 0).sum()\n",
    "            print(f\"Negative values in {column}: {negative_values}\\n\")\n",
    "        \n",
    "        # Document the issues\n",
    "        data_quality_issues[column] = {\n",
    "            'missing_values': missing_values,\n",
    "            'invalid_dates': invalid_dates if column in ['created_at', 'created_at_fee'] else None,\n",
    "            'negative_values': negative_values if column == 'total_amount_fee' else None\n",
    "        }\n",
    "    \n",
    "    return data_quality_issues\n",
    "\n",
    "# Columns to evaluate\n",
    "columns_to_evaluate = ['total_amount_fee', 'created_at', 'created_at_fee']\n",
    "\n",
    "# Evaluate data quality\n",
    "evaluate_data_quality_for_income(merged_df, columns_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Métricas Acumuladas por Cohorte:** Proponer y calcular métricas acumuladas que proporcionen perspectivas adicionales para la extracción de insights accionables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
